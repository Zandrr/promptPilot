<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ContextPilot</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <div class="container">
    <header class="hero">
      <h1>🧠 ContextPilot</h1>
      <p class="tagline">The prompt optimization platform that cuts costs and improves outputs for AI product teams.</p>
      <div class="cta">
        <input type="email" placeholder="Your email" />
        <button>Join Early Access</button>
      </div>
    </header>

    <section class="problems">
      <h2>❌ Context Should Be a Feature, Not a Hunch</h2>
      <div class="grid-3">
        <div class="card">
          <h3>🤯 Flying Blind: Most Context Goes Unused</h3>
          <p>You're injecting memory, metadata, summaries — but have no idea which elements actually improve outputs.</p>
        </div>
        <div class="card">
          <h3>💸 Token Waste: Ballooning LLM Costs</h3>
          <p>Tokens are cheaper, but costs add up fast when prompts are stuffed with "just in case" context.</p>
        </div>
        <div class="card">
          <h3>⚖️ Invisible Tradeoffs: Quality vs. Cost vs. Speed</h3>
          <p>No way to compare output quality, latency, and cost across strategies — until it hits production.</p>
        </div>
      </div>
    </section>

    <section class="solution-comparison">
      <h2>✅ From Guessing to Optimizing</h2>
      <div class="before-after">
        <div class="card">
          <h3>❌ Before ContextPilot</h3>
          <ul>
            <li>Hardcoded prompt logic with no way to test changes safely</li>
            <li>Manual copy/paste into playgrounds for tuning</li>
            <li>No clarity on token cost vs. output value</li>
            <li>Context added "just in case," not based on data</li>
            <li>Unknown impact on UX until users complain</li>
          </ul>
        </div>

        <div class="card highlight">
          <h3>✅ With ContextPilot</h3>
          <ul>
            <li>Modular prompt inputs treated like ML features</li>
            <li>Tests context variations automatically — real data, real outputs</li>
            <li>Side-by-side comparison of quality, latency, and cost</li>
            <li>Auto-identifies most effective context slice for each use case</li>
            <li>Deploys via SDK or config — no backend rewrites</li>
          </ul>
        </div>
      </div>
    </section>
    

    <section class="how-it-works">
      <h2>🚀 Find the Context That Actually Improves Output</h2>
      <p class="section-intro" style="text-align: center; margin-bottom: 30px; font-size: 1.2em;">
        <strong>ContextPilot shows you what data is available, lets you test new variables, and finds the best-performing combination — with full transparency.</strong>
      </p>
    
      <div class="grid-3">
        <div class="card">
          <h3>🔗 1. Connect Your Data</h3>
          <p>Upload a JSON file or connect live sources. We surface all available fields — from metadata to past interactions — even ones you may not have thought to use.</p>
        </div>
    
        <div class="card">
          <h3>🧠 2. Define Your Prompt</h3>
          <p>Use your real prompt with dynamic slots like <code>{{user_query}}</code> and <code>{{context}}</code>. No rewrites. You can manually inject variables to test or let us handle it.</p>
        </div>
    
        <div class="card">
          <h3>🔬 3. Run Context Experiments</h3>
          <p>We auto-generate multiple strategies using different combinations of inputs. You can include or exclude any variable to see how it affects output.</p>
        </div>
    
        <div class="card">
          <h3>📊 4. Compare Variations</h3>
          <p>See side-by-side results with real outputs. Compare quality, tone, token usage, latency — and discover what actually moves the needle.</p>
        </div>
    
        <div class="card">
          <h3>🚀 5. Deploy with One Line</h3>
          <p>Deploy the winning setup via SDK (dynamic) or export as a config (static). Either way, your app now uses the most efficient and effective context.</p>
    
          <details class="code-toggle">
            <summary>Show example code</summary>
            <div class="code-block">
              <h4>▶️ Option A: Live Fetch with SDK</h4>
              <pre><code>
    const context = await contextPilot.getContext({
      promptName: "support_reply",
      userId: "abc123"
    });
    
    const result = await llm.call({
      prompt: promptTemplate,
      context
    });
              </code></pre>
    
              <h4>📦 Option B: Export Static Strategy</h4>
              <pre><code>
    {
      "promptName": "support_reply",
      "contextBlocks": [
        "metadata.user_plan",
        "memory.last_3_messages",
        "summary.latest_issue"
      ]
    }
              </code></pre>
            </div>
          </details>
        </div>
      </div>
    </section>
    

    <section class="use-cases">
      <h2>🎯 The Right Context for the Right Experience</h2>
      <div class="grid-3">
        <div class="card">
          <h3>🤖 AI Assistants</h3>
          <p>Decide what to include from memory, user metadata, and previous queries to improve usefulness without bloat, creating more responsive assistants.</p>
        </div>
        <div class="card">
          <h3>💬 Support Bots</h3>
          <p>Test whether injecting past tickets or user profile data actually leads to better answers — or just increases cost and response time.</p>
        </div>
        <div class="card">
          <h3>📚 Personalized Tools</h3>
          <p>Figure out which inputs (e.g. history, preferences, summaries) actually impact tone, clarity, and quality for truly personalized experiences.</p>
        </div>
      </div>
    </section>

    <section class="value-props">
      <h2>💡 What You Get with ContextPilot</h2>
      <div class="grid-4">
        <div class="card"><strong>💰 Lower Costs</strong><br />Trim context size drastically without losing output quality.</div>
        <div class="card"><strong>⚡ Faster Iteration</strong><br />Test multiple prompt variations using live data — no backend changes required.</div>
        <div class="card"><strong>🧠 Smarter Decisions</strong><br />Compare quality, latency, and token cost side-by-side — with real examples.</div>
        <div class="card"><strong>🤖 Better Product UX</strong><br />Build LLM features that feel intelligent and responsive, not bloated and slow.</div>
      </div>
    </section>

    <section class="security">
      <h2>🔒 Security and Privacy by Default</h2>
      <p>We don’t store your prompts, responses, or API keys beyond testing. Everything runs client-authenticated and encrypted end-to-end. You stay in full control of your data — always..</p>
    </section>

    <section class="compatibility">
      <h2>🔌 Works Seamlessly With Your LLM Stack</h2>
      <p>
        Bring your own API keys — ContextPilot runs tests using your existing access to OpenAI, Anthropic, Cohere, and more. 
      </p>
      <p>
        Integrates directly with your orchestration tools like <strong>LangChain</strong>, <strong>LlamaIndex</strong>, and <strong>mem0</strong>, 
        so you can keep your memory systems and prompt versioning exactly as they are.
      </p>
      <p>
        Use our lightweight SDK to fetch optimized context at runtime, or export static configs to drop directly into your app logic. 
        No lock-in. No rewrites. Just better prompts.
      </p>
    </section>
    

    <section class="team-note">
      <h2>🧪 Built by LLM Engineers — for LLM Teams</h2>
      <p>Created by an ex-Twitter engineer and Meta PM with extensive experience building AI products. We were tired of playground spaghetti and manual testing, so we built the prompt optimization tool we needed ourselves.</p>
    </section>

    <section class="cta">
      <h2>📬 Try It Yourself</h2>
      <p><strong>Wondering if your prompts are bloated, brittle, or just ineffective? Join our exclusive early access program today.</strong></p>
      <input type="email" placeholder="Your email" />
      <button>Join Early Access</button>
      <p class="small">Limited slots available. No credit card required.</p>
    </section>
  </div>
</body>
</html>
